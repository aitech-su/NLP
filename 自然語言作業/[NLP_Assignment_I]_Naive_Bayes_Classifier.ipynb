{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "x6ZHOucvOOza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "nltk.download(\"movie_reviews\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK8D8UDUCZlc",
        "outputId": "eb39f9fe-54e3-4de6-dec9-34a61ec85b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter\n",
        "import math\n",
        "import random\n",
        "\n",
        "train_X, train_Y = [], []\n",
        "test_X, test_Y = [], []\n",
        "\n",
        "random.seed(0)\n",
        "for polarity in movie_reviews.categories():\n",
        "    for fid in movie_reviews.fileids(polarity):\n",
        "        if random.randrange(5) == 0:\n",
        "            test_X.append([w for w in movie_reviews.words(fid)])\n",
        "            test_Y.append(polarity)\n",
        "        else:\n",
        "            train_X.append([w for w in movie_reviews.words(fid)])\n",
        "            train_Y.append(polarity)\n",
        "\n",
        "print(train_X[0], train_Y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyfLD0SRChBr",
        "outputId": "d92dd9cc-e342-4468-e91f-a9aa0dfaaf94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an', 'accident', '.', 'one', 'of', 'the', 'guys', 'dies', ',', 'but', 'his', 'girlfriend', 'continues', 'to', 'see', 'him', 'in', 'her', 'life', ',', 'and', 'has', 'nightmares', '.', 'what', \"'\", 's', 'the', 'deal', '?', 'watch', 'the', 'movie', 'and', '\"', 'sorta', '\"', 'find', 'out', '.', '.', '.', 'critique', ':', 'a', 'mind', '-', 'fuck', 'movie', 'for', 'the', 'teen', 'generation', 'that', 'touches', 'on', 'a', 'very', 'cool', 'idea', ',', 'but', 'presents', 'it', 'in', 'a', 'very', 'bad', 'package', '.', 'which', 'is', 'what', 'makes', 'this', 'review', 'an', 'even', 'harder', 'one', 'to', 'write', ',', 'since', 'i', 'generally', 'applaud', 'films', 'which', 'attempt', 'to', 'break', 'the', 'mold', ',', 'mess', 'with', 'your', 'head', 'and', 'such', '(', 'lost', 'highway', '&', 'memento', ')', ',', 'but', 'there', 'are', 'good', 'and', 'bad', 'ways', 'of', 'making', 'all', 'types', 'of', 'films', ',', 'and', 'these', 'folks', 'just', 'didn', \"'\", 't', 'snag', 'this', 'one', 'correctly', '.', 'they', 'seem', 'to', 'have', 'taken', 'this', 'pretty', 'neat', 'concept', ',', 'but', 'executed', 'it', 'terribly', '.', 'so', 'what', 'are', 'the', 'problems', 'with', 'the', 'movie', '?', 'well', ',', 'its', 'main', 'problem', 'is', 'that', 'it', \"'\", 's', 'simply', 'too', 'jumbled', '.', 'it', 'starts', 'off', '\"', 'normal', '\"', 'but', 'then', 'downshifts', 'into', 'this', '\"', 'fantasy', '\"', 'world', 'in', 'which', 'you', ',', 'as', 'an', 'audience', 'member', ',', 'have', 'no', 'idea', 'what', \"'\", 's', 'going', 'on', '.', 'there', 'are', 'dreams', ',', 'there', 'are', 'characters', 'coming', 'back', 'from', 'the', 'dead', ',', 'there', 'are', 'others', 'who', 'look', 'like', 'the', 'dead', ',', 'there', 'are', 'strange', 'apparitions', ',', 'there', 'are', 'disappearances', ',', 'there', 'are', 'a', 'looooot', 'of', 'chase', 'scenes', ',', 'there', 'are', 'tons', 'of', 'weird', 'things', 'that', 'happen', ',', 'and', 'most', 'of', 'it', 'is', 'simply', 'not', 'explained', '.', 'now', 'i', 'personally', 'don', \"'\", 't', 'mind', 'trying', 'to', 'unravel', 'a', 'film', 'every', 'now', 'and', 'then', ',', 'but', 'when', 'all', 'it', 'does', 'is', 'give', 'me', 'the', 'same', 'clue', 'over', 'and', 'over', 'again', ',', 'i', 'get', 'kind', 'of', 'fed', 'up', 'after', 'a', 'while', ',', 'which', 'is', 'this', 'film', \"'\", 's', 'biggest', 'problem', '.', 'it', \"'\", 's', 'obviously', 'got', 'this', 'big', 'secret', 'to', 'hide', ',', 'but', 'it', 'seems', 'to', 'want', 'to', 'hide', 'it', 'completely', 'until', 'its', 'final', 'five', 'minutes', '.', 'and', 'do', 'they', 'make', 'things', 'entertaining', ',', 'thrilling', 'or', 'even', 'engaging', ',', 'in', 'the', 'meantime', '?', 'not', 'really', '.', 'the', 'sad', 'part', 'is', 'that', 'the', 'arrow', 'and', 'i', 'both', 'dig', 'on', 'flicks', 'like', 'this', ',', 'so', 'we', 'actually', 'figured', 'most', 'of', 'it', 'out', 'by', 'the', 'half', '-', 'way', 'point', ',', 'so', 'all', 'of', 'the', 'strangeness', 'after', 'that', 'did', 'start', 'to', 'make', 'a', 'little', 'bit', 'of', 'sense', ',', 'but', 'it', 'still', 'didn', \"'\", 't', 'the', 'make', 'the', 'film', 'all', 'that', 'more', 'entertaining', '.', 'i', 'guess', 'the', 'bottom', 'line', 'with', 'movies', 'like', 'this', 'is', 'that', 'you', 'should', 'always', 'make', 'sure', 'that', 'the', 'audience', 'is', '\"', 'into', 'it', '\"', 'even', 'before', 'they', 'are', 'given', 'the', 'secret', 'password', 'to', 'enter', 'your', 'world', 'of', 'understanding', '.', 'i', 'mean', ',', 'showing', 'melissa', 'sagemiller', 'running', 'away', 'from', 'visions', 'for', 'about', '20', 'minutes', 'throughout', 'the', 'movie', 'is', 'just', 'plain', 'lazy', '!', '!', 'okay', ',', 'we', 'get', 'it', '.', '.', '.', 'there', 'are', 'people', 'chasing', 'her', 'and', 'we', 'don', \"'\", 't', 'know', 'who', 'they', 'are', '.', 'do', 'we', 'really', 'need', 'to', 'see', 'it', 'over', 'and', 'over', 'again', '?', 'how', 'about', 'giving', 'us', 'different', 'scenes', 'offering', 'further', 'insight', 'into', 'all', 'of', 'the', 'strangeness', 'going', 'down', 'in', 'the', 'movie', '?', 'apparently', ',', 'the', 'studio', 'took', 'this', 'film', 'away', 'from', 'its', 'director', 'and', 'chopped', 'it', 'up', 'themselves', ',', 'and', 'it', 'shows', '.', 'there', 'might', \"'\", 've', 'been', 'a', 'pretty', 'decent', 'teen', 'mind', '-', 'fuck', 'movie', 'in', 'here', 'somewhere', ',', 'but', 'i', 'guess', '\"', 'the', 'suits', '\"', 'decided', 'that', 'turning', 'it', 'into', 'a', 'music', 'video', 'with', 'little', 'edge', ',', 'would', 'make', 'more', 'sense', '.', 'the', 'actors', 'are', 'pretty', 'good', 'for', 'the', 'most', 'part', ',', 'although', 'wes', 'bentley', 'just', 'seemed', 'to', 'be', 'playing', 'the', 'exact', 'same', 'character', 'that', 'he', 'did', 'in', 'american', 'beauty', ',', 'only', 'in', 'a', 'new', 'neighborhood', '.', 'but', 'my', 'biggest', 'kudos', 'go', 'out', 'to', 'sagemiller', ',', 'who', 'holds', 'her', 'own', 'throughout', 'the', 'entire', 'film', ',', 'and', 'actually', 'has', 'you', 'feeling', 'her', 'character', \"'\", 's', 'unraveling', '.', 'overall', ',', 'the', 'film', 'doesn', \"'\", 't', 'stick', 'because', 'it', 'doesn', \"'\", 't', 'entertain', ',', 'it', \"'\", 's', 'confusing', ',', 'it', 'rarely', 'excites', 'and', 'it', 'feels', 'pretty', 'redundant', 'for', 'most', 'of', 'its', 'runtime', ',', 'despite', 'a', 'pretty', 'cool', 'ending', 'and', 'explanation', 'to', 'all', 'of', 'the', 'craziness', 'that', 'came', 'before', 'it', '.', 'oh', ',', 'and', 'by', 'the', 'way', ',', 'this', 'is', 'not', 'a', 'horror', 'or', 'teen', 'slasher', 'flick', '.', '.', '.', 'it', \"'\", 's', 'just', 'packaged', 'to', 'look', 'that', 'way', 'because', 'someone', 'is', 'apparently', 'assuming', 'that', 'the', 'genre', 'is', 'still', 'hot', 'with', 'the', 'kids', '.', 'it', 'also', 'wrapped', 'production', 'two', 'years', 'ago', 'and', 'has', 'been', 'sitting', 'on', 'the', 'shelves', 'ever', 'since', '.', 'whatever', '.', '.', '.', 'skip', 'it', '!', 'where', \"'\", 's', 'joblo', 'coming', 'from', '?', 'a', 'nightmare', 'of', 'elm', 'street', '3', '(', '7', '/', '10', ')', '-', 'blair', 'witch', '2', '(', '7', '/', '10', ')', '-', 'the', 'crow', '(', '9', '/', '10', ')', '-', 'the', 'crow', ':', 'salvation', '(', '4', '/', '10', ')', '-', 'lost', 'highway', '(', '10', '/', '10', ')', '-', 'memento', '(', '10', '/', '10', ')', '-', 'the', 'others', '(', '9', '/', '10', ')', '-', 'stir', 'of', 'echoes', '(', '8', '/', '10', ')'] neg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Construction\n",
        "\n",
        "$\\bar{y} = \\text{arg}\\max_{y \\in \\mathbf{y}} P(y|x) = \\text{arg}\\max_{y \\in \\mathbf{y}} P(y) \\prod_{i=1}^n \\frac{P(x_i|y)}{P(x_i)} = \\text{arg}\\max_{y \\in \\mathbf{y}} P(y) \\prod_{i=1}^n P(x_i|y)$\n",
        "\n",
        "$P(x_i|y)=\\frac{C(x_i, y) + k}{C(y) + |\\mathbf{y}| \\times k}$\n",
        "\n",
        "$\\bar{y} = \\textrm{arg} \\max_{y \\in \\mathbf{y}} \\log P(y) + \\sum_{i=1}^n \\log \\frac{C(x_i, y) + k}{C(y) + k|\\mathbf{y}|}$\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "8TiSvHHAhy6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayesClassifier:\n",
        "    def __init__(self, k=0.5):\n",
        "        self.k = k\n",
        "        self.features = set()\n",
        "        self.class_feature_counts = defaultdict(Counter)\n",
        "        self.class_counts = Counter()\n",
        "        self.total = 0\n",
        "\n",
        "    def train(self, train_X, train_Y):\n",
        "        for tokens, label in zip(train_X, train_Y):\n",
        "            self.class_counts[label] += 1\n",
        "            self.total += 1\n",
        "            for token in set(tokens):\n",
        "                self.features.add(token)\n",
        "                self.class_feature_counts[label][token] += 1\n",
        "\n",
        "    def probabilities(self, token):\n",
        "        probs = {}\n",
        "        for cls, cls_cnt in self.class_counts.items():\n",
        "            probs[cls] = (self.class_feature_counts[cls][token] + self.k) / (cls_cnt + len(self.class_counts) * self.k)\n",
        "        return probs\n",
        "\n",
        "    def predict(self, tokens):\n",
        "        tokens = set(tokens)\n",
        "        log_probs = Counter()\n",
        "        for cls, cls_cnt in self.class_counts.items():\n",
        "            log_probs[cls] = math.log(cls_cnt / self.total)\n",
        "        for token in self.features:\n",
        "            probs = self.probabilities(token)\n",
        "            if token in tokens:\n",
        "                for cls, prob in probs.items():\n",
        "                    log_probs[cls] += math.log(prob)\n",
        "            else:\n",
        "                for cls, prob in probs.items():\n",
        "                    log_probs[cls] += math.log(1.0 - prob)\n",
        "        # Return the argmax of log_probs and all log_probs\n",
        "        return max(log_probs, key=log_probs.get), log_probs"
      ],
      "metadata": {
        "id": "fobAkWURDr6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the Model"
      ],
      "metadata": {
        "id": "GE_Ht04wh3Tc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NaiveBayesClassifier()\n",
        "model.train(train_X, train_Y)"
      ],
      "metadata": {
        "id": "5rdZQ-aJhtld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Taken from https://www.imdb.com/review/rw0990793/?ref_=tt_urv\n",
        "review = \"\"\"A whimsical, often spectacular view of a future in which advances in technology dominate the world. It is well shot and although slow-moving it is intense and enjoyable throughout. The featuring of classical music to establish atmosphere works brilliantly; it provides a feeling of awe, mystery and intrigue  the same aura that Walt Disney worked in creating 'Fantasia'. The special effects, both sound and visual, are still spellbinding by the standards of today's technology. Aside from the technical pluses of the film, it stands strong as it is one of not many films out there that has something important to say about humankind, and where the human race is heading in terms of our increasing reliance on machines and our unquenchable thirst to discover. Despite an ending that is hard to understand, it is even harder to overlook this film a true cinema classic.\"\"\"\n",
        "\n",
        "model.predict(word_tokenize(review))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeH93xRFZ1EF",
        "outputId": "b414df8e-4ed6-4bb4-d902-9adddaf5e49d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('pos', Counter({'neg': -608.7788406753601, 'pos': -603.0411839714244}))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct, total = 0, 0\n",
        "\n",
        "for x, y in zip(test_X, test_Y):\n",
        "    prediction, _ = model.predict(x)\n",
        "    if prediction == y:\n",
        "        correct += 1\n",
        "    total += 1\n",
        "\n",
        "print(\"%d / %d = %g\" % (correct, total, correct / total))"
      ],
      "metadata": {
        "id": "U1lkFRJ0FKbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b800c25-14bf-4212-cb26-456d0f4bbdc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "349 / 422 = 0.827014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring important features"
      ],
      "metadata": {
        "id": "pmqZUqeTgjzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prob_class_given_feature(feature, cls, model):\n",
        "    probs = model.probabilities(feature)\n",
        "    return probs[cls] / sum(probs.values())\n",
        "\n",
        "print(sorted(model.features, key=lambda t: prob_class_given_feature(t, \"pos\", model), reverse=True)[:30])\n",
        "print(sorted(model.features, key=lambda t: prob_class_given_feature(t, \"neg\", model), reverse=True)[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xofcbwlXgluq",
        "outputId": "bf854a8b-e734-4c10-d92d-652b4c901c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thematic', 'astounding', 'turturro', 'kenobi', 'reminder', 'naval', 'dread', 'seamless', 'en', 'fascination', 'denial', 'lovingly', 'ideology', 'masterfully', 'keen', 'ideals', 'timeless', 'balancing', 'supports', 'burbank', 'missteps', 'fabric', 'meryl', 'lofty', 'topping', 'uncut', 'online', 'musicals', 'strikingly', 'unemployed']\n",
            "['hudson', 'illogical', 'sans', 'yell', '3000', 'degenerates', 'overwrought', 'tedium', 'bio', 'undermines', 'pathetically', 'horrid', 'zellweger', 'biologist', 'lectures', 'batgirl', 'leaden', 'chevy', 'campiness', 'setups', 'stupidly', 'vomit', 'plodding', 'guinea', 'hmmm', 'charmless', 'abysmal', 'macpherson', 'oops', 'slain']\n"
          ]
        }
      ]
    }
  ]
}